{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from SStack import SStack\n",
    "from queue import Queue,LifoQueue\n",
    "import json\n",
    "import copy\n",
    "from py2neo import Graph,Node,Relationship,cypher\n",
    "\n",
    "test_graph = Graph('http://localhost:7474',username='neo4j',password='8611662')\n",
    "\n",
    "# 获取指定目录下的json文件\n",
    "def get_files(path='D:\\zyt\\\\azyt\\sfx', rule=\".json\"):\n",
    "    all = []\n",
    "    for fpathe,dirs,fs in os.walk(path):   # os.walk获取所有的目录\n",
    "        for f in fs:\n",
    "            filename = os.path.join(fpathe,f)\n",
    "            if filename.endswith(rule):  # 判断是否是\".json\"结尾\n",
    "                all.append(filename)\n",
    "    return all\n",
    "\n",
    "'''\n",
    "维护一个键的队列，输入参数为当前的属性名key和当前的队列的状态key_queue\n",
    "当遇到key为下面的值的时候，不仅弹出当前的key，还弹出其前一个即父类的key\n",
    "'''\n",
    "def preserve_key_queue(key, key_queue):\n",
    "    if key=='任免_辞职':\n",
    "        delete = key_queue.get()\n",
    "        delete = key_queue.get()\n",
    "    elif key=='社会兼职' or key=='人才培养类' or key=='博士后':\n",
    "        delete = key_queue.get()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "'''\n",
    "本函数用于处理倒数第二层属性并将其结果保存成dataframe\n",
    "接受参数为维护的栈和队列，以及对应的院士名\n",
    "当属性队列为空的时候，返回0\n",
    "'''\n",
    "def json_to_dataframe(st, key_queue, yuanshi_name_id):\n",
    "    if not st.is_empty():\n",
    "        content = set()\n",
    "        word = st.pop() #弹出当前栈里面顶上的内容\n",
    "        key_queue.put(word) #键值队列，用于保存前面已出现的键值(目的是方便后面迭代时能准确找到进行到什么地方了)\n",
    "        attribute_value_list = [] #局部列表变量，用于存储不同百科文件当前属性下的值\n",
    "        key_str = 'json_file'\n",
    "        for j in key_queue.queue: #通过维护的键的队列取到对应的键值\n",
    "            key_str += '[\\''+j+'\\']'\n",
    "        #print(\"  \",key_str)\n",
    "        attribute_value_list.append(eval(key_str))\n",
    "        flag = 0 #标记这几个百科json文件的当前属性值是否为空\n",
    "        for i in attribute_value_list:\n",
    "            if type(i).__name__ == 'list': #处理百科json文件中该属性下的值如果是列表时的情况，则取出列表里的每一个字典\n",
    "                flag = 1\n",
    "                if word=='人物影响' or word=='研究领域': #这两个属性的值没有子属性了，其值直接就是字符串形式，所以单独处理\n",
    "                    res = process_string(word, i, yuanshi_name_id)\n",
    "                    key = key_queue.get()\n",
    "                    preserve_key_queue(key, key_queue)\n",
    "                    json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "                elif word=='人才培养类':\n",
    "                    res = process_list_no_same(word, i, yuanshi_name_id) #返回的是一个列表，列表里面是多个字典\n",
    "                    key = key_queue.get()\n",
    "                    preserve_key_queue(key, key_queue) #得到动态维护的键的队列\n",
    "                    json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "                else: #其他情况的属性值里还有子属性，此时如果是列表的话也是单独处理\n",
    "                    res = process_list(word, i, yuanshi_name_id) #返回的是一个列表，列表里面是多个字典\n",
    "                    key = key_queue.get()\n",
    "                    preserve_key_queue(key, key_queue) #得到动态维护的键的队列\n",
    "                    json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "                break\n",
    "            elif type(i).__name__ == 'dict': #处理百科json文件中该属性下的值如果是字典时的情况，这里主要是针对单属性值\n",
    "                flag = 1\n",
    "                except_word = ['人物履历','教育经历','工作经历','其他职务','主要成果']\n",
    "                if word not in except_word:\n",
    "                    res = process_dict(word, i, yuanshi_name_id)\n",
    "                    key = key_queue.get()\n",
    "                    preserve_key_queue(key, key_queue)\n",
    "                    json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "                else: #当不是单属性值时，说明其还不是最外层的属性(也即为父属性)，则将其压入栈中后续出栈时再处理\n",
    "                    dict_key1 = list(i.keys()) #将字典里的键都放入栈中，稍后依次取出进行对齐\n",
    "                    dict_key1.reverse()\n",
    "                    for i in dict_key1:\n",
    "                        st.push(i)\n",
    "                    json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        if flag==0: #表示这几个文件的当前属性都为空\n",
    "            key = key_queue.get()\n",
    "            preserve_key_queue(key, key_queue)\n",
    "            json_to_dataframe(st, key_queue, yuanshi_name_id)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "''' \n",
    "用于查看当前的值是否已经存在于原dataframe里了，若存在则查看是否已经被连线过了\n",
    "若没有连线，则添加一条边，若有连线则依次拥有相同值的下一个，若都有连线，则新加入一行\n",
    "'''\n",
    "def line2frame(word, content, yuanshi_name_id):\n",
    "    global used_node_flag\n",
    "    global count_id\n",
    "    global used_node_flag #表示已使用过的节点集合\n",
    "    global node\n",
    "    global relation\n",
    "    if content in node['name'].values: #如果当前处理的值在已有的dataframe已经存在\n",
    "        relative_content_line = node.loc[node['name']==content] #在原有dataframe里找出所有该值对应的行\n",
    "        flag = 0\n",
    "        for i in relative_content_line['id'].values:\n",
    "            if i in used_node_flag: #如果该id已经被处理过，则查看下一个\n",
    "                continue\n",
    "            else:\n",
    "                new_relation_dict = {'from_id':yuanshi_name_id, 'pro1':word, 'to_id':i}\n",
    "                new_relation_line = pd.DataFrame(new_relation_dict,index=[0])\n",
    "                relation = relation.append(new_relation_line,ignore_index=True)\n",
    "                used_node_flag.append(i) #标志为已被处理过\n",
    "                flag = 1 #表示找到了没被处理过的有相同值的行\n",
    "                break\n",
    "        if flag==0: #表示所有该值对应的行都被处理过\n",
    "            write_to_dataframe(word, content, yuanshi_name_id, count_id)\n",
    "            count_id += 1\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        write_to_dataframe(word, content, yuanshi_name_id, count_id)\n",
    "        count_id += 1\n",
    "    \n",
    "# 用于将处理结果存入dataframe里\n",
    "def write_to_dataframe(word, content, yuanshi_name_id, to_id):\n",
    "    global node\n",
    "    global relation\n",
    "    new_node_dict = {'id':to_id, 'name':content}\n",
    "    new_node_line = pd.DataFrame(new_node_dict,index=[0])\n",
    "    new_relation_dict = {'from_id':yuanshi_name_id, 'pro1':word, 'to_id':to_id}\n",
    "    new_relation_line = pd.DataFrame(new_relation_dict,index=[0])\n",
    "    node = node.append(new_node_line,ignore_index=True)\n",
    "    relation = relation.append(new_relation_line,ignore_index=True)\n",
    "    \n",
    "#处理人物影响、研究领域时转化为dataframe的情况 \n",
    "def process_string(word, attribute_value, yuanshi_name_id):\n",
    "    content = ''\n",
    "    for i in attribute_value:\n",
    "        content += i\n",
    "    line2frame(word, content, yuanshi_name_id)\n",
    "\n",
    "# 处理人才培养里面有教育理念和指导学生这两种情况\n",
    "def process_list_no_same(word, attribute_value_list, yuanshi_name_id):\n",
    "    if len(attribute_value_list)==2:\n",
    "        content1 = attribute_value_list[0]['教育理念']\n",
    "        content2 = attribute_value_list[1]['指导学生']\n",
    "        line2frame('教育理念', content1, yuanshi_name_id)\n",
    "        line2frame('指导学生', content2, yuanshi_name_id)\n",
    "    else:\n",
    "        if '教育理念' in attribute_value_list[0].keys():\n",
    "            content = attribute_value_list[0]['教育理念']\n",
    "            line2frame('教育理念', content, yuanshi_name_id)\n",
    "        if '指导学生' in attribute_value_list[0].keys():\n",
    "            content = attribute_value_list[0]['指导学生']\n",
    "            line2frame('指导学生', content, yuanshi_name_id)\n",
    "    \n",
    "# 处理其他除人物影响、研究领域外的list的情况\n",
    "def process_list(word, attribute_value_list, yuanshi_name_id):\n",
    "    keys = attribute_value_list[0].keys()\n",
    "    list_key = ['所获奖项','授予奖项名称','论著名称','散文名称','项目名称','研究成果名称','专利名称','教育理念','指导学生','事件','语录','争议起因','事件起因','方向']\n",
    "    for i in attribute_value_list:\n",
    "        content = ''\n",
    "        if '组织机构' in keys:\n",
    "            if i['组织机构']=='' and i['职位_职称']=='':\n",
    "                continue\n",
    "            content = i['组织机构'] + i['职位_职称']\n",
    "            line2frame(word, content, yuanshi_name_id)\n",
    "        elif '任免职位_职称' in keys:\n",
    "            if i['任免职位_职称']=='':\n",
    "                continue\n",
    "            content = i['信息公布权威机关'] + i['任免职位_职称']\n",
    "            line2frame(word, content, yuanshi_name_id)\n",
    "        elif '所在单位' in keys:\n",
    "            if i['所在单位']=='' and i['职位_职称']=='':\n",
    "                continue\n",
    "            content = i['所在单位'] + i['职位_职称']\n",
    "            line2frame(word, content, yuanshi_name_id)\n",
    "        elif '演讲_报告题目' in keys:\n",
    "            if i['组织单位_活动单位名称']=='' and i['演讲_报告题目']=='':\n",
    "                continue\n",
    "            content = i['组织单位_活动单位名称'] + i['演讲_报告题目']\n",
    "            line2frame(word, content, yuanshi_name_id)\n",
    "        else:\n",
    "            for key in keys:\n",
    "                if key in list_key:\n",
    "                    if i[key]=='':\n",
    "                        continue\n",
    "                    content = i[key]\n",
    "                    line2frame(key, content, yuanshi_name_id)\n",
    "\n",
    "# 用于处理字典的情况\n",
    "def process_dict(word, attribute_value_list, yuanshi_name_id):\n",
    "    keys = attribute_value_list.keys()\n",
    "    key_list = ['外文名','性别','出生日期','出生地','国籍','民族','职业','毕业院校','政治面貌','代表作品','主要成就','曾任职','信仰','原籍','学校名称']\n",
    "    for key in keys:\n",
    "        content = ''\n",
    "        if (key in key_list) and (type(attribute_value_list[key]).__name__ == 'dict'):\n",
    "            content = attribute_value_list[key][key]\n",
    "            if word=='基本信息':\n",
    "                line2frame(key, content, yuanshi_name_id)\n",
    "            else:\n",
    "                line2frame(word, content, yuanshi_name_id)\n",
    "        elif (key in key_list) and (type(attribute_value_list[key]).__name__ == 'list'):\n",
    "            for i in attribute_value_list[key]:\n",
    "                if word=='基本信息':\n",
    "                    content = i[key]\n",
    "                    line2frame(key, content, yuanshi_name_id)\n",
    "                else:\n",
    "                    content = i[key]\n",
    "                    line2frame(word, content, yuanshi_name_id)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def process_entrace(key_list, yuanshi_name_id):\n",
    "    st = SStack() #用栈存放每一轮的属性\n",
    "    lq = LifoQueue(maxsize=0) #用后进先出队列用于存放文件操作过程中的中间键值(用于新建新的对齐json)\n",
    "    key_list.reverse() #属性名列表反向，为了使最后按照正向的方式写入\n",
    "    for i in key_list:\n",
    "        st.push(i) #将最开始外层的属性名压入栈中\n",
    "    res = json_to_dataframe(st, lq, yuanshi_name_id) #调用处理成dataframe的函数\n",
    "    global node\n",
    "    global relation\n",
    "    node.to_csv('E://neo4j/import/fang_node2.csv',index=False) #将df输出到csv文件，输出顺序为dataframe默认的列名顺序\n",
    "    relation.to_csv('E://neo4j/import/fang_relation2.csv',index=False)\n",
    "    # 表示先删除当前已有的节点和关系\n",
    "    cypher_delete = '''MATCH(b) detach delete b\n",
    "                  '''\n",
    "    test_graph.run(cypher_delete)\n",
    "    # 表示加载节点到neo4j\n",
    "    cypher_node = '''LOAD CSV WITH HEADERS FROM \"file:///fang_node2.csv\" AS line\n",
    "                     MERGE (p:test{id:line.id,name:line.name})\n",
    "                  '''\n",
    "    test_graph.run(cypher_node)\n",
    "    # 表示加载关系到neo4j\n",
    "    cypher_relation = '''LOAD CSV WITH HEADERS FROM \"file:///fang_relation2.csv\" AS line  \n",
    "                         match (from:test{id:line.from_id}),(to:test{id:line.to_id})  \n",
    "                         merge (from)-[r:rel{pro1:line.pro1}]->(to)\n",
    "                      '''\n",
    "    test_graph.run(cypher_relation)\n",
    "\n",
    "def deal_yuanshinameid_and_in_process_entrnce(every_baike_json, json_file):\n",
    "    global count_id\n",
    "    global used_node_flag\n",
    "    global node\n",
    "    global relation\n",
    "    used_node_flag = [] #定义一个列表，记录已使用节点\n",
    "    key_list = list(json_file.keys()) #局部变量，用于存放百科json文件的最外层父属性(院士名和百科名不计算)\n",
    "    yuanshi_name = every_baike_json['院士名']\n",
    "    last_line_value = node['id'][-1:].values[0] #取出当前已存在csv文件的最后一行节点的id号\n",
    "    count_id = last_line_value + 1 #由该id号的下一个数后开始进行增加\n",
    "    #院士名这个节点单独处理\n",
    "    new_node = pd.DataFrame()\n",
    "    new_node[\"id\"] = [count_id]\n",
    "    new_node[\"name\"] = [yuanshi_name]\n",
    "    node = pd.concat([node, new_node], axis=0, ignore_index=True)\n",
    "    #院士中文名这个关系单独处理\n",
    "    new_relation = pd.DataFrame()\n",
    "    new_relation[\"from_id\"] = [count_id]\n",
    "    new_relation[\"pro1\"] = ['中文名']\n",
    "    new_relation[\"to_id\"] = [count_id]\n",
    "    relation = pd.concat([relation, new_relation], axis=0, ignore_index=True)\n",
    "    yuanshi_name_id = count_id #将院士名这个ID保存下来\n",
    "    count_id += 1\n",
    "    process_entrace(key_list, yuanshi_name_id)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global node\n",
    "    global relation\n",
    "    global json_file #全局列表变量，用于存放不同百科json文件的内容\n",
    "    node = pd.read_csv(\"./node.csv\")\n",
    "    relation = pd.read_csv(\"./relation.csv\")\n",
    "    b = get_files(r\"./\")\n",
    "    for i in b:\n",
    "        if i.split('./')[1]!='fang_final.json':\n",
    "            with open(i,'r',encoding='utf-8') as f: #打开json文件并保存到json文件列表里\n",
    "                every_baike_json = json.load(f)\n",
    "                json_file = every_baike_json\n",
    "            deal_yuanshinameid_and_in_process_entrnce(every_baike_json, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "node = pd.read_csv(\"./node.csv\")\n",
    "last_line_value = node['id'][-1:].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除：\n",
    "# 删除所有节点和关系：\n",
    "# START n=node(*) \n",
    "# match n-[r]-()\n",
    "# delete n,r;\n",
    "# 删除所有节点以上方法过时，后面版本将被遗弃-推荐使用如下方法\n",
    "# MATCH (n)\n",
    "# OPTIONAL MATCH (n)-[r]-()\n",
    "# DELETE n,r\n",
    "\n",
    "# MATCH(b) detach delete b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   北京邮电大学校长\n",
      "   计算机系助教/讲师/副教授\n",
      "   计算机系教授\n",
      "   哈尔滨工业大学计算机与电气工程学院副院长\n",
      "   中国国家计算机网络与信息安全管理中心副总工程师\n",
      "   国家计算机网络应急技术处理协调中心总工程师/副主任/教授级高级工程师\n",
      "   国家计算机网络应急技术处理协调中心主任/总工程师/教授级高级工程师\n",
      "   信息产业部互联网应急处理协调办公室主任\n",
      "   国家计算机网络与信息安全管理中心名誉主任\n",
      "   北京邮电大学校长\n",
      "   哈尔滨工业大学计算机系计算机系统结构教研室副主任、主任\n",
      "   哈尔滨工业大学网络中心主任\n",
      "   中国工程院院士\n",
      "   国家计算机网络与信息安全管理中心名誉主任\n",
      "   中国网络空间安全协会理事长\n",
      "   哈尔滨工业大学（深圳）计算机科学与技术学院教授、首席学术顾问\n",
      "   广州大学网络空间先进技术研究院名誉院长\n",
      "   哈尔滨工业大学\n",
      "   国家计算机网络与信息安全管理中心总工程师、副主任、教授级高级工程师\n",
      "   中国科学院计算技术研究所客座研究员、博士生导师、信息安全首席科学家\n",
      "   国家计算机网络与信息安全管理中心主任、总工程师、教授级高级工程师、名誉主任\n",
      "   国防科学技术大学兼职教授、特聘教授、博士生导师\n",
      "   第十一届全国人大第十一届全国人大代表\n",
      "   北邮基层人大代表\n",
      "   中国科学院信息工程研究所客座研究员、博士生导师\n",
      "   中国科学院信息工程研究所学术委员会主任\n",
      "   中国网络空间安全协会第一届理事会理事长\n",
      "   哈尔滨工业大学计算机系助教/讲师/副教授/教研室副主任\n",
      "   哈尔滨工业大学计算机系教授\n",
      "   哈尔滨工业大学计算机系博士生导师\n",
      "   国家计算机网络应急技术处理协调中心\n",
      "   国防科学技术大学\n",
      "   哈尔滨工业大学\n",
      "   哈尔滨工业大学\n",
      "   清华大学\n",
      "   中国通信标准化协会理事\n",
      "   中国互联网协会副理事长\n",
      "   网络与信息安全工作委员会主任\n",
      "   中国通信学会学术工作委员会委员\n",
      "   清华大学计算机系教授\n",
      "   中科院计算所客座研究员/博士生导师/信息安全首席科学家\n",
      "   国防科学技术大学教授/博士生导师\n",
      "   《通信学报》编辑委员会主任\n",
      "   中国计算机学会副理事长/计算机安全专业委员会主任\n",
      "   信息产业部通信科学技术委员会常务委员\n",
      "   哈尔滨工业大学教授、博士生导师\n",
      "   哈尔滨工业大学国家计算机内容安全重点实验室主任\n",
      "   “新世纪百千万人才工程国家级人选”评审委员会委员\n",
      "   中国科学院计算所客座研究员、博士生导师、信息安全首席科学家\n",
      "   《通信学报》编辑委员会主任\n",
      "   国家自然科学基金可信软件重大专项专家组副组长\n",
      "   计算机安全专业委员会主任\n",
      "   哈尔滨工业大学（深圳）计算机学院首席学术顾问\n",
      "   中国云安全与新兴技术安全创新联盟理事长\n",
      "   教育部网络空间安全学科评议组召集人\n",
      "   中国中文信息学会第八届理事会理事长\n",
      "   网络与信息安全技术委员会主席\n",
      "   专家咨询委员会委员\n",
      "   技术管理委员会委员\n",
      "   中国下一代互联网示范工程（CNGI）项目专家委员会委员\n",
      "   《国家计算机网络与信息安全管理中心科学技术委员会主任\n",
      "   上海市互联网宣传管理技术咨询专家\n",
      "   北京市公安交通管理局专家顾问团成员\n",
      "   北京市信息化专家咨询委员会委员\n",
      "   中国网络通信集团公司技术委员会委员\n",
      "   财政部“金财工程”专家咨询委员会委员\n",
      "   中华人民共和国第十一届全国人民代表大会代表\n",
      "   中国电子信息产业集团首席科学家\n",
      "   网络与信息安全技术委员会主席/专家咨询委员会委员/技术管理委员会委员\n",
      "   通信安全技术委员会主任\n",
      "   中国下一代互联网示范工程项目专家委员会委员\n",
      "   全国人大信息化系统改造和建设工程专家咨询顾问组成员\n",
      "   国家863计划“十一五”信息技术专家委员会委员\n",
      "   国家自然科学基金可信软件重大专项专家组副组长\n",
      "   国家973计划“信息安全理论及若干关键技术”首席科学家\n",
      "   信息产业部通信科学技术委员会常务委员\n",
      "   国家计算机网络与信息安全管理中心科学技术委员会主任\n",
      "   解放军总后勤部信息化专家咨询委员会委员\n",
      "   国家信息安全产品认证管理委员会委员\n",
      "   国家信息化专家咨询委员会委员\n",
      "   国家应急管理专家组成员\n",
      "   公安部信息安全特聘专家\n",
      "   “新世纪百千万人才工程国家级人选”评审委员会委员\n",
      "   国家信息安全产品认证委员会委员\n",
      "   中国网络通信集团公司技术委员会委员\n",
      "   国家863计划“十一五”信息技术领域专家委员会委员\n",
      "   信息内容安全技术国家工程实验室主任\n",
      "   国家八六三计划信息安全主题组专家\n",
      "   国家发展改革委信息安全专家咨询组成员\n",
      "   哈尔滨工业大学国家计算机内容安全重点实验室主任\n",
      "   解放军总后勤部信息化专家咨询委员会委员\n",
      "   中国通信学会会士、常务理事\n",
      "   清华大学计算机系兼职教授\n",
      "   全国人大信息化系统改造和建设工程专家咨询顾问组顾问组成员\n",
      "   哈尔滨工业大学教授、博士生导师\n",
      "   北京市公安交通管理局专家顾问团成员\n",
      "   中国科学院计算所客座研究员、博士生导师、信息安全首席科学家\n",
      "   国防科学技术大学特聘教授、博士生导师\n",
      "   《通信学报》编辑委员会主任\n",
      "   国家自然科学基金可信软件重大专项专家组副组长\n",
      "   中国计算机学会副理事长\n",
      "   计算机安全专业委员会主任\n",
      "   中华人民共和国第十一届全国人民代表大会大会代表\n",
      "   哈尔滨工业大学（深圳）计算机学院首席学术顾问\n",
      "   中国中文信息学会第八届理事会理事长\n",
      "   中国电子信息产业集团首席科学家\n",
      "   可信分布式计算与服务教育部重点实验室（北京邮电大学）主任实验室主任\n",
      "   中国云安全与新兴技术安全创新联盟理事长\n",
      "   教育部网络空间安全学科评议组召集人\n",
      "   世界互联网大会《物联网搜索技术》\n",
      "   中国共产党\n",
      "   男\n",
      "   汉族\n",
      "   江西省上饶市万年县\n",
      "   中国网络空间安全协会理事长\n",
      "   2005年当选为中国工程院院士\n",
      "   《论网络空间主权》、《在线社交网络分析》\n",
      "   计算机病毒及其对策,通信学报\n",
      "   《论网络空间主权》《在线社交网络分析》\n",
      "   黑龙江省哈尔滨市\n",
      "   中国\n",
      "   1960-7-17\n",
      "   学者，教授\n",
      "   国家计算机网络应急技术处理协调中心主任\n",
      "   计算机科学家、信息安全专家、中国工程院院士\n",
      "   科研工作者\n",
      "   无\n",
      "   Bin xing Fang\n",
      "   北京邮电大学校长\n",
      "   哈尔滨工业大学，清华大学\n",
      "   哈尔滨工业大学\n",
      "   国务院政府特殊津贴\n",
      "   “先进个人”称号\n",
      "   “在信息产业部重点工程中做出突出贡献特等奖先进个人”称号\n",
      "   “新世纪百千万人才工程国家级人选”\n",
      "   信息产业科技创新先进工作者\n",
      "   何梁何利基金科学与技术进步奖\n",
      "   中国工程院院士\n",
      "   部级科学进步二等奖\n",
      "   部级科学进步三等奖\n",
      "   杰出人才\n",
      "   全国“杰出专业技术人才”荣誉称号\n",
      "   国务院政府特殊津贴专家\n",
      "   中国信息安全保障突出贡献奖\n",
      "   中国互联网年度人物特别贡献奖\n",
      "   网络空间安全人才培养存在三个特殊性：一是自身网络安全的特殊性；二是人才特殊性；三是网络空间安全人才培养的特殊性\n",
      "   培养硕士与博士生百余名\n",
      "   信息安全管理系统\n",
      "   大范围宽带网络动态处置系统\n",
      "   大规模网络信息获取系统\n",
      "   搜索引擎安全管理系统\n",
      "   通信数据安全管理系统\n",
      "   非常规突发事件中网络舆情作用机制与相关技术研究\n",
      "   Web搜索与挖掘的新理论和新方法—支持舆情监控的Web搜索与挖掘的理论与方法研究国家自然科学基金重点研究计划项目\n",
      "   Web搜索与挖掘的新理论和新方法—支持舆情监控的Web搜索与挖掘的理论与方法研究\n",
      "   网络环境下特定信息获取与处理技术国防科技创新团队项目\n",
      "   下一代互联网舆情管理系统应用示范\n",
      "   大规模网络入侵定位与容忍\n",
      "   信息安全理论及若干关键技术国家973项目\n",
      "   非常规突发事件中网络舆情作用机制与相关技术研究国家自然科学基金重大研究计划培育项目\n",
      "   《计算机病毒及其对策》\n",
      "   《计算机病毒及其防范》\n",
      "   建设网络应急体系,保障网络空间安全\n",
      "   《ECLIPSE MV/8000超级小型机产品介绍》\n",
      "   《网和天下 三网融合理论、实验与信息安全》\n",
      "   《在线社交网络分析》\n",
      "   《论网络空间主权》\n",
      "   计算机病毒及其预防技术\n",
      "   国家信息安全展略研究\n",
      "   大规模网络信息获取系统\n",
      "   支持存储器无冲突访问的互连开关门阵列芯片的研制\n",
      "   多机系统的性能评价的研究\n",
      "   支持存储器无冲突访问的互连开关设计理论及方法\n",
      "   ABC-90阵列计算机综合模拟器\n",
      "   国家信息安全管理系统\n",
      "   支持存储器无冲突访问的互联网络开关门阵列芯片的研制\n",
      "   搜索引擎安全管理系统\n",
      "   国家通信数据安全管理系统\n",
      "   在线社交网络分析关键技术及系统\n",
      "   大规模网络安全态势分析关键技术及系统YHSAS\n",
      "   计算机安全事件入侵检测\n",
      "   国家信息安全基础设施\n",
      "  True\n"
     ]
    }
   ],
   "source": [
    "for i in node['name'][1:]:\n",
    "    print(\"  \",i)\n",
    "    pass\n",
    "if '中国工程院院士' in node['name'].values:\n",
    "    print(\"  True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19\n",
      "   34\n",
      "   35\n",
      "   132\n"
     ]
    }
   ],
   "source": [
    "temp = node.loc[node['name']=='哈尔滨工业大学']\n",
    "for i  in temp['id'].values:\n",
    "    print(\"  \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
